{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1-CustomeModelTensorFlow.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahoopuspanjali/PracticalMachineLearning/blob/master/HW1_CustomeModelTensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnCbi5ZAL9vV",
        "colab_type": "code",
        "outputId": "1452e2b5-a96a-4fb5-8db6-32b5ad8c827a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip install --upgrade tensorflow\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.4.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.7)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.9.11)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2oy658HA5HU",
        "colab_type": "code",
        "outputId": "511aebb6-a930-4658-8645-3ebec51effc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT9Fjn_ldHgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.datasets import boston_housing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dcBeIihdld2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reLlxit1LlVw",
        "colab_type": "text"
      },
      "source": [
        "1.Import boston dataset from keras\n",
        "2.devide the data in Train / Test split- print the shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv19ijEgazyb",
        "colab_type": "code",
        "outputId": "89a0b721-6945-4e55-d27c-d87006ff85f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "print(f'Training data shape : {X_train.shape}')\n",
        "print(f'Testing data shape : {X_test.shape}')\n",
        "print(f'y_train shape : {y_train.shape}')\n",
        "print(f'y_test shape : {y_test.shape}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape : (404, 13)\n",
            "Testing data shape : (102, 13)\n",
            "y_train shape : (404,)\n",
            "y_test shape : (102,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqmLstUCMBip",
        "colab_type": "text"
      },
      "source": [
        "3.Explore data - print it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPqOjhLjdm3E",
        "colab_type": "code",
        "outputId": "c4e419e5-1279-4721-c80c-095b5edf8e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.23247e+00 0.00000e+00 8.14000e+00 ... 2.10000e+01 3.96900e+02\n",
            "  1.87200e+01]\n",
            " [2.17700e-02 8.25000e+01 2.03000e+00 ... 1.47000e+01 3.95380e+02\n",
            "  3.11000e+00]\n",
            " [4.89822e+00 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.75520e+02\n",
            "  3.26000e+00]\n",
            " ...\n",
            " [3.46600e-02 3.50000e+01 6.06000e+00 ... 1.69000e+01 3.62250e+02\n",
            "  7.83000e+00]\n",
            " [2.14918e+00 0.00000e+00 1.95800e+01 ... 1.47000e+01 2.61950e+02\n",
            "  1.57900e+01]\n",
            " [1.43900e-02 6.00000e+01 2.93000e+00 ... 1.56000e+01 3.76700e+02\n",
            "  4.38000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVDYe45KkSYq",
        "colab_type": "code",
        "outputId": "27ab6715-5e3b-4713-e4c6-87f19254aedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4 12.1 17.9 23.1 19.9\n",
            " 15.7  8.8 50.  22.5 24.1 27.5 10.9 30.8 32.9 24.  18.5 13.3 22.9 34.7\n",
            " 16.6 17.5 22.3 16.1 14.9 23.1 34.9 25.  13.9 13.1 20.4 20.  15.2 24.7\n",
            " 22.2 16.7 12.7 15.6 18.4 21.  30.1 15.1 18.7  9.6 31.5 24.8 19.1 22.\n",
            " 14.5 11.  32.  29.4 20.3 24.4 14.6 19.5 14.1 14.3 15.6 10.5  6.3 19.3\n",
            " 19.3 13.4 36.4 17.8 13.5 16.5  8.3 14.3 16.  13.4 28.6 43.5 20.2 22.\n",
            " 23.  20.7 12.5 48.5 14.6 13.4 23.7 50.  21.7 39.8 38.7 22.2 34.9 22.5\n",
            " 31.1 28.7 46.  41.7 21.  26.6 15.  24.4 13.3 21.2 11.7 21.7 19.4 50.\n",
            " 22.8 19.7 24.7 36.2 14.2 18.9 18.3 20.6 24.6 18.2  8.7 44.  10.4 13.2\n",
            " 21.2 37.  30.7 22.9 20.  19.3 31.7 32.  23.1 18.8 10.9 50.  19.6  5.\n",
            " 14.4 19.8 13.8 19.6 23.9 24.5 25.  19.9 17.2 24.6 13.5 26.6 21.4 11.9\n",
            " 22.6 19.6  8.5 23.7 23.1 22.4 20.5 23.6 18.4 35.2 23.1 27.9 20.6 23.7\n",
            " 28.  13.6 27.1 23.6 20.6 18.2 21.7 17.1  8.4 25.3 13.8 22.2 18.4 20.7\n",
            " 31.6 30.5 20.3  8.8 19.2 19.4 23.1 23.  14.8 48.8 22.6 33.4 21.1 13.6\n",
            " 32.2 13.1 23.4 18.9 23.9 11.8 23.3 22.8 19.6 16.7 13.4 22.2 20.4 21.8\n",
            " 26.4 14.9 24.1 23.8 12.3 29.1 21.  19.5 23.3 23.8 17.8 11.5 21.7 19.9\n",
            " 25.  33.4 28.5 21.4 24.3 27.5 33.1 16.2 23.3 48.3 22.9 22.8 13.1 12.7\n",
            " 22.6 15.  15.3 10.5 24.  18.5 21.7 19.5 33.2 23.2  5.  19.1 12.7 22.3\n",
            " 10.2 13.9 16.3 17.  20.1 29.9 17.2 37.3 45.4 17.8 23.2 29.  22.  18.\n",
            " 17.4 34.6 20.1 25.  15.6 24.8 28.2 21.2 21.4 23.8 31.  26.2 17.4 37.9\n",
            " 17.5 20.   8.3 23.9  8.4 13.8  7.2 11.7 17.1 21.6 50.  16.1 20.4 20.6\n",
            " 21.4 20.6 36.5  8.5 24.8 10.8 21.9 17.3 18.9 36.2 14.9 18.2 33.3 21.8\n",
            " 19.7 31.6 24.8 19.4 22.8  7.5 44.8 16.8 18.7 50.  50.  19.5 20.1 50.\n",
            " 17.2 20.8 19.3 41.3 20.4 20.5 13.8 16.5 23.9 20.6 31.5 23.3 16.8 14.\n",
            " 33.8 36.1 12.8 18.3 18.7 19.1 29.  30.1 50.  50.  22.  11.9 37.6 50.\n",
            " 22.7 20.8 23.5 27.9 50.  19.3 23.9 22.6 15.2 21.7 19.2 43.8 20.3 33.2\n",
            " 19.9 22.5 32.7 22.  17.1 19.  15.  16.1 25.1 23.7 28.7 37.2 22.6 16.4\n",
            " 25.  29.8 22.1 17.4 18.1 30.3 17.5 24.7 12.6 26.5 28.7 13.3 10.4 24.4\n",
            " 23.  20.  17.8  7.  11.8 24.4 13.8 19.4 25.2 19.4 19.4 29.1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKsL4OkKfJMV",
        "colab_type": "code",
        "outputId": "1c2f6f10-90ad-4b6c-935c-b098dd232ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(f'Training data shape : {X_train.shape}')\n",
        "print(f'Testing data shape : {X_test.shape}')\n",
        "print(f'Training sample : {X_train[0]}')\n",
        "print(f'Testing sample : {X_test[0]}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape : (404, 13)\n",
            "Testing data shape : (102, 13)\n",
            "Training sample : [  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
            "   3.9769    4.      307.       21.      396.9      18.72   ]\n",
            "Testing sample : [ 18.0846   0.      18.1      0.       0.679    6.434  100.       1.8347\n",
            "  24.     666.      20.2     27.25    29.05  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcYHBK7jMWjR",
        "colab_type": "text"
      },
      "source": [
        "4.Normalize the X values using sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwHGI5eIgXP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHtYRA1yiCrZ",
        "colab_type": "code",
        "outputId": "ed23c44d-fce9-4e81-a77f-a8ce7e9e66a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "min_max_scaler = MinMaxScaler()\n",
        "X_train_scale = min_max_scaler.fit_transform(X_train)\n",
        "print(X_train_scale)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.37816304e-02 0.00000000e+00 2.81524927e-01 ... 8.93617021e-01\n",
            "  1.00000000e+00 4.68818985e-01]\n",
            " [1.73654275e-04 8.25000000e-01 5.75513196e-02 ... 2.23404255e-01\n",
            "  9.96167230e-01 3.80794702e-02]\n",
            " [5.49837765e-02 0.00000000e+00 6.46627566e-01 ... 8.08510638e-01\n",
            "  9.46089061e-01 4.22185430e-02]\n",
            " ...\n",
            " [3.18534767e-04 3.50000000e-01 2.05278592e-01 ... 4.57446809e-01\n",
            "  9.12627969e-01 1.68322296e-01]\n",
            " [2.40852297e-02 0.00000000e+00 7.00879765e-01 ... 2.23404255e-01\n",
            "  6.59715568e-01 3.87969095e-01]\n",
            " [9.07048543e-05 6.00000000e-01 9.05425220e-02 ... 3.19148936e-01\n",
            "  9.49064501e-01 7.31236203e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgwmJBtBumdY",
        "colab_type": "code",
        "outputId": "53de81f9-6cef-4e12-e6a0-5ee4ec013a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(X_train_scale[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01378163 0.         0.28152493 0.         0.31481481 0.49980635\n",
            " 0.91452111 0.29719123 0.13043478 0.22753346 0.89361702 1.\n",
            " 0.46881898]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8x3Ly9pekzq",
        "colab_type": "code",
        "outputId": "72fd510a-a308-46f2-85ab-22a2a7d367c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X_test_scale = min_max_scaler.fit_transform(X_test)\n",
        "print(X_test_scale[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.72190697 0.         0.63650075 0.         0.59916493 0.39846154\n",
            " 1.         0.0346309  1.         0.91412214 0.87804878 0.00698455\n",
            " 0.90222813]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBRUqg-cNIaF",
        "colab_type": "code",
        "outputId": "9eed633f-3228-4528-ce77-34b0eeb58042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBcfO_5JNuTX",
        "colab_type": "text"
      },
      "source": [
        "Configuring the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pQ8MHKlikBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.Input(shape=(13,))\n",
        "x = keras.layers.Dense(32, activation='relu')(inputs)\n",
        "y = keras.layers.Dense(32, activation='relu')(x)\n",
        "outputs = keras.layers.Dense(1, activation='sigmoid')(y)\n",
        "model1 = keras.Model(inputs, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J4ku_Mxk2Wb",
        "colab_type": "code",
        "outputId": "6dcc058b-b5e5-4f44-a004-7b44b72e0966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "source": [
        "model1.compile(loss='mse',optimizer='adam')\n",
        "h1 = model1.fit(X_train_scale, y_train,batch_size=64, epochs=50,validation_data=(X_test_scale, y_test) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 404 samples, validate on 102 samples\n",
            "Epoch 1/50\n",
            "404/404 [==============================] - 1s 2ms/sample - loss: 567.9714 - val_loss: 595.3701\n",
            "Epoch 2/50\n",
            "404/404 [==============================] - 0s 101us/sample - loss: 565.2249 - val_loss: 592.4893\n",
            "Epoch 3/50\n",
            "404/404 [==============================] - 0s 98us/sample - loss: 562.5291 - val_loss: 589.6736\n",
            "Epoch 4/50\n",
            "404/404 [==============================] - 0s 107us/sample - loss: 559.7320 - val_loss: 586.7731\n",
            "Epoch 5/50\n",
            "404/404 [==============================] - 0s 107us/sample - loss: 556.8720 - val_loss: 583.8334\n",
            "Epoch 6/50\n",
            "404/404 [==============================] - 0s 108us/sample - loss: 554.0053 - val_loss: 580.9863\n",
            "Epoch 7/50\n",
            "404/404 [==============================] - 0s 115us/sample - loss: 551.3487 - val_loss: 578.4484\n",
            "Epoch 8/50\n",
            "404/404 [==============================] - 0s 105us/sample - loss: 549.0583 - val_loss: 576.3598\n",
            "Epoch 9/50\n",
            "404/404 [==============================] - 0s 103us/sample - loss: 547.1739 - val_loss: 574.7360\n",
            "Epoch 10/50\n",
            "404/404 [==============================] - 0s 108us/sample - loss: 545.7251 - val_loss: 573.5448\n",
            "Epoch 11/50\n",
            "404/404 [==============================] - 0s 102us/sample - loss: 544.7004 - val_loss: 572.6789\n",
            "Epoch 12/50\n",
            "404/404 [==============================] - 0s 92us/sample - loss: 543.9417 - val_loss: 572.0762\n",
            "Epoch 13/50\n",
            "404/404 [==============================] - 0s 106us/sample - loss: 543.4534 - val_loss: 571.6724\n",
            "Epoch 14/50\n",
            "404/404 [==============================] - 0s 109us/sample - loss: 543.1361 - val_loss: 571.4117\n",
            "Epoch 15/50\n",
            "404/404 [==============================] - 0s 101us/sample - loss: 542.9255 - val_loss: 571.2442\n",
            "Epoch 16/50\n",
            "404/404 [==============================] - 0s 99us/sample - loss: 542.7967 - val_loss: 571.1312\n",
            "Epoch 17/50\n",
            "404/404 [==============================] - 0s 105us/sample - loss: 542.7074 - val_loss: 571.0530\n",
            "Epoch 18/50\n",
            "404/404 [==============================] - 0s 100us/sample - loss: 542.6455 - val_loss: 570.9954\n",
            "Epoch 19/50\n",
            "404/404 [==============================] - 0s 99us/sample - loss: 542.5989 - val_loss: 570.9500\n",
            "Epoch 20/50\n",
            "404/404 [==============================] - 0s 100us/sample - loss: 542.5624 - val_loss: 570.9130\n",
            "Epoch 21/50\n",
            "404/404 [==============================] - 0s 100us/sample - loss: 542.5328 - val_loss: 570.8820\n",
            "Epoch 22/50\n",
            "404/404 [==============================] - 0s 104us/sample - loss: 542.5087 - val_loss: 570.8561\n",
            "Epoch 23/50\n",
            "404/404 [==============================] - 0s 103us/sample - loss: 542.4883 - val_loss: 570.8349\n",
            "Epoch 24/50\n",
            "404/404 [==============================] - 0s 101us/sample - loss: 542.4718 - val_loss: 570.8177\n",
            "Epoch 25/50\n",
            "404/404 [==============================] - 0s 106us/sample - loss: 542.4580 - val_loss: 570.8035\n",
            "Epoch 26/50\n",
            "404/404 [==============================] - 0s 107us/sample - loss: 542.4470 - val_loss: 570.7915\n",
            "Epoch 27/50\n",
            "404/404 [==============================] - 0s 108us/sample - loss: 542.4378 - val_loss: 570.7813\n",
            "Epoch 28/50\n",
            "404/404 [==============================] - 0s 104us/sample - loss: 542.4300 - val_loss: 570.7729\n",
            "Epoch 29/50\n",
            "404/404 [==============================] - 0s 108us/sample - loss: 542.4234 - val_loss: 570.7654\n",
            "Epoch 30/50\n",
            "404/404 [==============================] - 0s 108us/sample - loss: 542.4178 - val_loss: 570.7591\n",
            "Epoch 31/50\n",
            "404/404 [==============================] - 0s 100us/sample - loss: 542.4130 - val_loss: 570.7537\n",
            "Epoch 32/50\n",
            "404/404 [==============================] - 0s 109us/sample - loss: 542.4088 - val_loss: 570.7489\n",
            "Epoch 33/50\n",
            "404/404 [==============================] - 0s 106us/sample - loss: 542.4051 - val_loss: 570.7447\n",
            "Epoch 34/50\n",
            "404/404 [==============================] - 0s 134us/sample - loss: 542.4020 - val_loss: 570.7409\n",
            "Epoch 35/50\n",
            "404/404 [==============================] - 0s 110us/sample - loss: 542.3991 - val_loss: 570.7377\n",
            "Epoch 36/50\n",
            "404/404 [==============================] - 0s 130us/sample - loss: 542.3967 - val_loss: 570.7348\n",
            "Epoch 37/50\n",
            "404/404 [==============================] - 0s 114us/sample - loss: 542.3945 - val_loss: 570.7322\n",
            "Epoch 38/50\n",
            "404/404 [==============================] - 0s 106us/sample - loss: 542.3927 - val_loss: 570.7299\n",
            "Epoch 39/50\n",
            "404/404 [==============================] - 0s 114us/sample - loss: 542.3910 - val_loss: 570.7279\n",
            "Epoch 40/50\n",
            "404/404 [==============================] - 0s 112us/sample - loss: 542.3894 - val_loss: 570.7260\n",
            "Epoch 41/50\n",
            "404/404 [==============================] - 0s 104us/sample - loss: 542.3880 - val_loss: 570.7242\n",
            "Epoch 42/50\n",
            "404/404 [==============================] - 0s 101us/sample - loss: 542.3867 - val_loss: 570.7227\n",
            "Epoch 43/50\n",
            "404/404 [==============================] - 0s 114us/sample - loss: 542.3856 - val_loss: 570.7213\n",
            "Epoch 44/50\n",
            "404/404 [==============================] - 0s 111us/sample - loss: 542.3846 - val_loss: 570.7200\n",
            "Epoch 45/50\n",
            "404/404 [==============================] - 0s 105us/sample - loss: 542.3837 - val_loss: 570.7189\n",
            "Epoch 46/50\n",
            "404/404 [==============================] - 0s 109us/sample - loss: 542.3828 - val_loss: 570.7179\n",
            "Epoch 47/50\n",
            "404/404 [==============================] - 0s 102us/sample - loss: 542.3821 - val_loss: 570.7169\n",
            "Epoch 48/50\n",
            "404/404 [==============================] - 0s 97us/sample - loss: 542.3814 - val_loss: 570.7161\n",
            "Epoch 49/50\n",
            "404/404 [==============================] - 0s 107us/sample - loss: 542.3808 - val_loss: 570.7153\n",
            "Epoch 50/50\n",
            "404/404 [==============================] - 0s 102us/sample - loss: 542.3802 - val_loss: 570.7145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JasYuErFOJw3",
        "colab_type": "text"
      },
      "source": [
        "5.Create custom activation function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwcdzx3wX5C4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_sigmoid(x):\n",
        "    return (tf.sigmoid(x) * 5) - 1\n",
        "\n",
        "def my_relu(z): # return value is just max of 0 and z\n",
        "    return tf.maximum(0.,z)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy2ALhJ7rJgi",
        "colab_type": "text"
      },
      "source": [
        "6.Create custom initializer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD_0TC5HrMpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_glorot_initializer(shape, dtype=tf.float32):\n",
        "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao25oiaPrXq5",
        "colab_type": "text"
      },
      "source": [
        "Building model with custom activation function and Custom initializer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbNjkQgNZSBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.Input(shape=(13,))\n",
        "x = keras.layers.Dense(32, activation=my_relu, \n",
        "                           kernel_initializer=my_glorot_initializer)(inputs)\n",
        "y = keras.layers.Dense(32, activation=my_relu,\n",
        "                           kernel_initializer=my_glorot_initializer)(x)\n",
        "outputs = keras.layers.Dense(1, activation=my_sigmoid)(y)\n",
        "\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoEWNvBJN-6p",
        "colab_type": "text"
      },
      "source": [
        "7.Create custom loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu7bbhZ_wLcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def huber_fn(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < 1\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss  = tf.abs(error) - 0.9\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EwSsgTmPzez",
        "colab_type": "text"
      },
      "source": [
        "8.Train your model using your custom functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx8aKFh3XunM",
        "colab_type": "code",
        "outputId": "bcca78f9-4bd3-446d-e698-e7e84eead448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "source": [
        "model.compile(loss=huber_fn, optimizer=\"nadam\")\n",
        "h = model.fit(X_train_scale, y_train,batch_size=64, epochs=50, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 323 samples, validate on 81 samples\n",
            "Epoch 1/50\n",
            "323/323 [==============================] - 1s 3ms/sample - loss: 19.3627 - val_loss: 20.8148\n",
            "Epoch 2/50\n",
            "323/323 [==============================] - 0s 101us/sample - loss: 19.1657 - val_loss: 20.6002\n",
            "Epoch 3/50\n",
            "323/323 [==============================] - 0s 81us/sample - loss: 18.9287 - val_loss: 20.3300\n",
            "Epoch 4/50\n",
            "323/323 [==============================] - 0s 91us/sample - loss: 18.6387 - val_loss: 20.0188\n",
            "Epoch 5/50\n",
            "323/323 [==============================] - 0s 88us/sample - loss: 18.3193 - val_loss: 19.6999\n",
            "Epoch 6/50\n",
            "323/323 [==============================] - 0s 94us/sample - loss: 18.0110 - val_loss: 19.4236\n",
            "Epoch 7/50\n",
            "323/323 [==============================] - 0s 88us/sample - loss: 17.7594 - val_loss: 19.2206\n",
            "Epoch 8/50\n",
            "323/323 [==============================] - 0s 91us/sample - loss: 17.5820 - val_loss: 19.0793\n",
            "Epoch 9/50\n",
            "323/323 [==============================] - 0s 95us/sample - loss: 17.4611 - val_loss: 18.9876\n",
            "Epoch 10/50\n",
            "323/323 [==============================] - 0s 85us/sample - loss: 17.3838 - val_loss: 18.9272\n",
            "Epoch 11/50\n",
            "323/323 [==============================] - 0s 89us/sample - loss: 17.3334 - val_loss: 18.8854\n",
            "Epoch 12/50\n",
            "323/323 [==============================] - 0s 90us/sample - loss: 17.2982 - val_loss: 18.8554\n",
            "Epoch 13/50\n",
            "323/323 [==============================] - 0s 98us/sample - loss: 17.2729 - val_loss: 18.8343\n",
            "Epoch 14/50\n",
            "323/323 [==============================] - 0s 93us/sample - loss: 17.2553 - val_loss: 18.8188\n",
            "Epoch 15/50\n",
            "323/323 [==============================] - 0s 97us/sample - loss: 17.2423 - val_loss: 18.8072\n",
            "Epoch 16/50\n",
            "323/323 [==============================] - 0s 92us/sample - loss: 17.2325 - val_loss: 18.7985\n",
            "Epoch 17/50\n",
            "323/323 [==============================] - 0s 94us/sample - loss: 17.2253 - val_loss: 18.7915\n",
            "Epoch 18/50\n",
            "323/323 [==============================] - 0s 87us/sample - loss: 17.2195 - val_loss: 18.7861\n",
            "Epoch 19/50\n",
            "323/323 [==============================] - 0s 88us/sample - loss: 17.2149 - val_loss: 18.7816\n",
            "Epoch 20/50\n",
            "323/323 [==============================] - 0s 94us/sample - loss: 17.2111 - val_loss: 18.7778\n",
            "Epoch 21/50\n",
            "323/323 [==============================] - 0s 90us/sample - loss: 17.2079 - val_loss: 18.7747\n",
            "Epoch 22/50\n",
            "323/323 [==============================] - 0s 88us/sample - loss: 17.2053 - val_loss: 18.7721\n",
            "Epoch 23/50\n",
            "323/323 [==============================] - 0s 92us/sample - loss: 17.2031 - val_loss: 18.7698\n",
            "Epoch 24/50\n",
            "323/323 [==============================] - 0s 88us/sample - loss: 17.2012 - val_loss: 18.7678\n",
            "Epoch 25/50\n",
            "323/323 [==============================] - 0s 92us/sample - loss: 17.1996 - val_loss: 18.7661\n",
            "Epoch 26/50\n",
            "323/323 [==============================] - 0s 131us/sample - loss: 17.1981 - val_loss: 18.7645\n",
            "Epoch 27/50\n",
            "323/323 [==============================] - 0s 128us/sample - loss: 17.1968 - val_loss: 18.7632\n",
            "Epoch 28/50\n",
            "323/323 [==============================] - 0s 135us/sample - loss: 17.1957 - val_loss: 18.7620\n",
            "Epoch 29/50\n",
            "323/323 [==============================] - 0s 143us/sample - loss: 17.1947 - val_loss: 18.7609\n",
            "Epoch 30/50\n",
            "323/323 [==============================] - 0s 132us/sample - loss: 17.1938 - val_loss: 18.7600\n",
            "Epoch 31/50\n",
            "323/323 [==============================] - 0s 116us/sample - loss: 17.1930 - val_loss: 18.7591\n",
            "Epoch 32/50\n",
            "323/323 [==============================] - 0s 155us/sample - loss: 17.1923 - val_loss: 18.7583\n",
            "Epoch 33/50\n",
            "323/323 [==============================] - 0s 128us/sample - loss: 17.1916 - val_loss: 18.7575\n",
            "Epoch 34/50\n",
            "323/323 [==============================] - 0s 142us/sample - loss: 17.1910 - val_loss: 18.7569\n",
            "Epoch 35/50\n",
            "323/323 [==============================] - 0s 127us/sample - loss: 17.1904 - val_loss: 18.7562\n",
            "Epoch 36/50\n",
            "323/323 [==============================] - 0s 126us/sample - loss: 17.1899 - val_loss: 18.7557\n",
            "Epoch 37/50\n",
            "323/323 [==============================] - 0s 128us/sample - loss: 17.1894 - val_loss: 18.7551\n",
            "Epoch 38/50\n",
            "323/323 [==============================] - 0s 129us/sample - loss: 17.1890 - val_loss: 18.7546\n",
            "Epoch 39/50\n",
            "323/323 [==============================] - 0s 121us/sample - loss: 17.1886 - val_loss: 18.7541\n",
            "Epoch 40/50\n",
            "323/323 [==============================] - 0s 123us/sample - loss: 17.1882 - val_loss: 18.7537\n",
            "Epoch 41/50\n",
            "323/323 [==============================] - 0s 127us/sample - loss: 17.1879 - val_loss: 18.7534\n",
            "Epoch 42/50\n",
            "323/323 [==============================] - 0s 137us/sample - loss: 17.1876 - val_loss: 18.7530\n",
            "Epoch 43/50\n",
            "323/323 [==============================] - 0s 129us/sample - loss: 17.1873 - val_loss: 18.7527\n",
            "Epoch 44/50\n",
            "323/323 [==============================] - 0s 131us/sample - loss: 17.1870 - val_loss: 18.7524\n",
            "Epoch 45/50\n",
            "323/323 [==============================] - 0s 137us/sample - loss: 17.1868 - val_loss: 18.7522\n",
            "Epoch 46/50\n",
            "323/323 [==============================] - 0s 126us/sample - loss: 17.1866 - val_loss: 18.7519\n",
            "Epoch 47/50\n",
            "323/323 [==============================] - 0s 131us/sample - loss: 17.1864 - val_loss: 18.7517\n",
            "Epoch 48/50\n",
            "323/323 [==============================] - 0s 126us/sample - loss: 17.1862 - val_loss: 18.7514\n",
            "Epoch 49/50\n",
            "323/323 [==============================] - 0s 133us/sample - loss: 17.1860 - val_loss: 18.7512\n",
            "Epoch 50/50\n",
            "323/323 [==============================] - 0s 124us/sample - loss: 17.1858 - val_loss: 18.7510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3aWAHqqSHxn",
        "colab_type": "text"
      },
      "source": [
        "9.Visualize the history of your training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xlWcDLJaF9a",
        "colab_type": "code",
        "outputId": "c521dbd1-9e9e-450e-e02e-164c67e8cb35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title('Loss / Mean Squared Error')\n",
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJMsp0YuIZDklehGRLPf/ASvASbnP2OyDAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnDb2C-lg96m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}